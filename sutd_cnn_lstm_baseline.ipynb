{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SUTD TrafficQA \u2014 CNN + LSTM baseline (MCQ-4)\n",
        "\n",
        "This notebook runs the **CNN+LSTM** multiple-choice baseline (4 options) that mirrors the classic LSTM-style setup described in the SUTD-TrafficQA paper:\n",
        "- **BiLSTM** encodes the question and each candidate answer (QA Bank)\n",
        "- **CNN** encodes sampled frames\n",
        "- **LSTM** encodes the frame sequence\n",
        "- An **MLP** scores each of the 4 options\n",
        "\n",
        "## Expected dataset layout\n",
        "```\n",
        "CS412-CV-FinalProject-main/\n",
        "  SUTD/\n",
        "    videos/\n",
        "      *.mp4\n",
        "    questions/\n",
        "      R3_train.jsonl\n",
        "      R3_val.jsonl\n",
        "      R3_test.jsonl\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) (Optional) Install dependencies\n",
        "If you're running in a fresh environment, uncomment the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# %pip install -r requirements.txt\n",
        "# If you hit a torchvision import error in your environment, this baseline still runs using a small CNN fallback.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Point to your project + dataset\n",
        "Set `PROJECT_ROOT` to the folder that contains `train_sutd_cnn_lstm.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# If this notebook lives in the repo root, keep '.'\n",
        "PROJECT_ROOT = Path('.').resolve()\n",
        "print('PROJECT_ROOT:', PROJECT_ROOT)\n",
        "\n",
        "# Make 'src/' importable\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "# Update this if your SUTD folder is elsewhere\n",
        "SUTD_ROOT = PROJECT_ROOT / 'SUTD'\n",
        "print('SUTD_ROOT:', SUTD_ROOT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Sanity check the dataset structure\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "videos_dir = SUTD_ROOT / 'videos'\n",
        "questions_dir = SUTD_ROOT / 'questions'\n",
        "\n",
        "print('videos_dir exists:', videos_dir.exists())\n",
        "print('questions_dir exists:', questions_dir.exists())\n",
        "if questions_dir.exists():\n",
        "    print('question files:', sorted([p.name for p in questions_dir.glob('*.jsonl')])[:10])\n",
        "if videos_dir.exists():\n",
        "    vids = list(videos_dir.glob('*'))\n",
        "    print('num videos:', len(vids))\n",
        "    print('sample videos:', [v.name for v in vids[:5]])\n",
        "\n",
        "train_file = questions_dir / 'R3_train.jsonl'\n",
        "val_file   = questions_dir / 'R3_val.jsonl'\n",
        "test_file  = questions_dir / 'R3_test.jsonl'\n",
        "print('train file:', train_file, 'exists:', train_file.exists())\n",
        "print('val file:', val_file, 'exists:', val_file.exists())\n",
        "print('test file:', test_file, 'exists:', test_file.exists())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Quick smoke test (small subset)\n",
        "This runs a short training to verify everything works.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "NUM_FRAMES = 16\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 1\n",
        "\n",
        "!python train_sutd_cnn_lstm.py \\\n",
        "  --sutd_root \"{SUTD_ROOT}\" \\\n",
        "  --num_frames {NUM_FRAMES} \\\n",
        "  --batch_size {BATCH_SIZE} \\\n",
        "  --epochs {EPOCHS} \\\n",
        "  --max_train_samples 200 \\\n",
        "  --max_val_samples 200 \\\n",
        "  --use_train_aug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Full training\n",
        "Remove the `--max_*_samples` flags to train on the full split.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Uncomment to train fully\n",
        "# NUM_FRAMES = 16\n",
        "# BATCH_SIZE = 8\n",
        "# EPOCHS = 5\n",
        "#\n",
        "# !python train_sutd_cnn_lstm.py \\\n",
        "#   --sutd_root \"{SUTD_ROOT}\" \\\n",
        "#   --num_frames {NUM_FRAMES} \\\n",
        "#   --batch_size {BATCH_SIZE} \\\n",
        "#   --epochs {EPOCHS} \\\n",
        "#   --use_train_aug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Evaluate a checkpoint\n",
        "By default, training writes:\n",
        "- `outputs/sutd_cnn_lstm/best.pt`\n",
        "- `outputs/sutd_cnn_lstm/last.pt`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "ckpt = PROJECT_ROOT / 'outputs' / 'sutd_cnn_lstm' / 'best.pt'\n",
        "print('Using ckpt:', ckpt, 'exists:', ckpt.exists())\n",
        "\n",
        "!python eval_sutd_cnn_lstm.py \\\n",
        "  --sutd_root \"{SUTD_ROOT}\" \\\n",
        "  --ckpt \"{ckpt}\" \\\n",
        "  --num_frames {NUM_FRAMES}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Suggested ablations (good for your report)\n",
        "- **Frame count**: `--num_frames 8/16/32/64`\n",
        "- **Backbone**: `--cnn_backbone resnet18` vs `resnet50`\n",
        "- **Augmentation**: toggle `--use_train_aug`\n",
        "- **Freeze CNN**: (default freeze) remove `--freeze_cnn` if you want to finetune the visual encoder\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}